## Virtuelle Adressierung

![](./assets/Screenshot%202023-06-18%20173953.png)

> Beschreiben Sie die einstufige virtuelle Adressierung.

* Die Bildung der realen Adresse erfolgt in 2 Schritten.
* Die virtuelle Adresse wird in der MMU (Memory Management Unit) in 2 Teile zerlegt.
* Der rechte Teil (Offset) wird vorerst beiseitegelegt.
* Der linke Teil (Page) wird als Index in der Seitentabelle verwendet.
* Der Wert des Page-Index wird verwendet, um den entsprechenden Eintrag in der Seitentabelle auszuw√§hlen.
* Der ausgew√§hlte Eintrag enth√§lt eine Wert mit 20 Bit (Real Page), der mit dem Offset kombiniert wird.
* Die resultierende Adresse wird als reale Adresse bezeichnet und wird zur Adressierung im Speicher verwendet.
* Die Adresse der Seitentabelle wird im Steuerregister CR3 des Prozessors oder der MMU gespeichert.
* Durch √Ñndern des Offset-Werts bleibt die Adressierung innerhalb derselben Seite, w√§hrend sich der Wert der realen Seite √§ndern kann, was auf einen anderen Speicherbereich verweist.

> Welche Bedeutung haben die Eintr√§ge in der Page-Tabelle?

In der Page-Tabelle sind die Real-Pages drinnen, aus denen anhand des Offsets die Reelle Adresse errechnet wird.

---

> **In einem 32-Bit-System mit `4kB` gro√üen Seiten wird die zweistufige virtuelle Adressierung eingesetzt.**
> 
> Wie viele Speicher und wie viele Tabellen braucht man mindestens f√ºr die Speichertabellen (PD, PT)
> eines kleinen Programms (mit Code, Date, Heap und Stack)?

```
2 PT, 1 PD (kleines Programm)

32 Bit -> 10 PD, 10 PT, 12 Offset

2^10 = 1024 Eintraege in dem PD
Jeder der Eintraege hat 32 Bit

=> Insgesamt 1024 * 32 Bit = 4 KiB

2^10 = 1024 Eintraege in der PT (= 4 KiB)

=> Insgesamt 4 KiB (PD) + 2 * 4 KiB (PT) = 12 KiB fuer die Tabellen

Falls fuer Code noch Speicher, dann noch `4 * 4 KiB` (4 KiB pro Page)
evtl. `2 * 4` KiB falls Daten, Code und Heap in ein Page kann

=> Insgesamt Insgesamt 28 KiB
```

> Wozu dient der TLB?

Der TLB (Translation Lookaside Buffer) ist ein Cache, der verwendet wird, um die Adress√ºbersetzung bei der virtuellen Adressierung zu beschleunigen. Er enth√§lt die k√ºrzlich verwendeten √úbersetzungseintr√§ge (virtuelle Adresse zu physischer Adresse), um den Zugriff auf die Tabellen zu vermeiden.

Wenn ein Programm eine virtuelle Adresse verwendet, schaut der Prozessor zuerst im TLB nach, ob die √úbersetzung vorhanden ist. Wenn ja, wird die physische Adresse direkt aus dem TLB abgerufen. Dieser Vorgang ist viel schneller als der Zugriff auf die Tabellen im Speicher.

Wenn die √úbersetzung jedoch nicht im TLB vorhanden ist (ein sogenannter TLB-Miss), muss der Prozessor auf die Speichertabellen zugreifen, um die √úbersetzung zu finden. In diesem Fall dauert die Adress√ºbersetzung l√§nger, da der Speicherzugriff zeitaufw√§ndiger ist als der Zugriff auf den TLB.
 
> F√ºr welche Bereiche des virtuellen Adressraums werden diese ben√∂tigt?

Daten, Code und Heap liegen am Anfang des v. A. Stack an Ende.
Deswegen wird fuer den Anfang und fuer das Ende ein PT gebraucht, welche beide im PD zu finden sind, welcher den gesamten virtuellen Adressraum abbildet.

---

> **Virtuelle Adressierung bei 32-Bit mit `4MB` Seiten.**
>
> Wie wird die Virtuelle Adresse aufgeteilt (quantitativ)?

Bei 4MB Seiten wird dem Offset 22 Bit zugeteilt und der Page 10 Bit anstatt bei bspw. 4 KiB Seiten, wo der Offset 12 Bit und Page 20 Bit bekommt.

> Wie "berechnet" die MMU dabei die reelle Adresse (Zeichnung)?
> **od.:** Beschreiben Sie die Funktionsweise der virtuellen Adressierung eines 32-Bit-Prozessors mit einer Seitengr√∂√üe von 4MB

![](./assets/Screenshot%202023-06-18%20213555.png)

> Wie wird durch die virtuelle Adressierung verhindert, dass Programme auf fremden Adressraum zugreifen?

Anhand des P und W Bits. Ist (P = 0) oder (W = 0), so wird eine Exception ausgeloest. Dadurch wird die Anwendung unterbrochen.

> Wie vermeidet man, dass bei jeder Speicheradressierung die vollst√§ndige Adressumsetzung erfolgen muss?

TLB

---

> ![](./assets/SCR-20230618-ohri.png)
> 
> Beschreiben Sie, wie die reelle Adresse gebildet wird

Gleich wie bei der zweistufigen, nur mit 4 Stufen.

* PM schaut in PMLE Tabelle nach naechsten Wert, dieser referenziert auf PDPE Tabelle (fuer jeden Eintrag gibt es eine Tabelle)
* gleiches Spiel in dieser PDPE Tabelle
* gleiches Spiel in dieser PDE Tabelle
* gleiches Spiel in dieser PTE Tabelle
* Eintrag der PTE Tabelle mit Offset zusammenrechnen
* Erhaelt reelle Adresse

> Wie gro√ü sind die Register?

* 2^9 Eintraege pro Tabelle
* (falls ein Eintrag 64 Bit gross ist, dann 2 ^ 9 * 64 Bit (= 512*64/8 Bytes = 4 KiB)) | HILFE

> Warum ist diese Tabellengr√∂√üe gew√§hlt? Was kann man tun, um gr√∂√üere Seiten hinzubekommen?

Optimum aus Zugriffzeiten bei Miss und Speicherbedarf.
Bei invalidem Eintrag (P = 0) kann man sich die folgenden Tabellen sparen.

Um groessere Seiten hinzubekommen muss man die Tabellen verkleinern und den Offset vergroessern. 
Fuer 4 MB Seiten zum Beispiel 22 Bit Offset, fuer 4 KB nur 12 Bit Offset.

---

> ![](./assets/image.png)
> 
> **Gegeben sei die virtuelle Adresse `0x5678` und der Anfang der Page-Tabelle (Einstufige Adressumsetzung, Seitengr√∂√üe `4kB`)**
>
> Ermitteln Sie die reelle Adresse im Hauptspeicher

`0x5678` -> 0x5 (Page) 0x678 (Offset). An Index 5 in der Tabelle (6. Eintrag) steht `0x1234`. Ergbnis = `0x1234` + `0x678` = `0x1234678`

> Was geschieht, wenn dort ein Wert eingetragen wird?

P = Present (1. Spalte), W = Writable (2. Spalte). Falls (P = 0), dann existiert Tabelle nicht. Falls (W = 0), dann Tabelle nicht beschreibbar.
Da bei `0x1234678` (W = 0) ist, kann dort nicht beschrieben werden. Es wird eine Exception geworfen.

---

> Warum wird die einstufige virtuelle Adressierung nicht verwendet?

Auch fuer kleine Anwendungen muss die komplette Tabelle erstellt werden. Dadurch gibt es einen sehr hohen Speicheraufwand.

> Wie arbeitet die virtuelle Adressierung tats√§chlich?

In echt verwendet man die Mehrstufige virtuelle Adressierung.

Bei der mehrstufigen virtuellen Adressierung wird die virtuelle Adresse in mehrere Teile aufgeteilt und durch mehrere Tabellenstufen geleitet, um die physische Adresse zu bestimmen. Der Index jeder Tabelle wird verwendet, um den Eintrag in der n√§chsten Tabelle zu finden, bis schlie√ülich die physische Adresse erreicht wird (anhand von Kombination mit Offset). Dies erm√∂glicht eine effiziente Nutzung des virtuellen Adressraums und eine flexiblere Speicherverwaltung.

---






## Dateisysteme

> Funktionsweise ext4

` üö® answer missing `

---

> Funktionsweise ext2

` üö® answer missing `

---

> Funktionsweise FAT

` üö® answer missing `

---

> [ext4] Beschreiben Sie den Aufbau des Dateisystems `ext4`

` üö® answer missing `

---

> [ext4] Beschreiben Sie die Funktionsweise des ext4-Dateisystems mit Extents

` üö® answer missing `

---

> `[ext4]` Warum kann ext4 mit Extents gr√∂√üere Partitionen verwalten als ohne Extents

` üö® answer missing `

---

> `[ext4]` Wie gro√ü kann eine Datei werden (Blockgr√∂√üe 4 KiB, Rechenweg)

```
BN = 32 Bit (immer bei ext4)
Pro Datei = 2^32 Bloecke
BS = 4 KiB
Max. Datei = Anz. Bloecke * BS
           = 2^32 * 4 KiB = 16 TB
```

---

> **Gegeben sei ein ext2-Dateisystem mit einer Blockgr√∂√üe von `4 KiB`.
> Im Dateikopf seien 12 Eintr√§ge f√ºr die direkte Adressierung von Datenbl√∂cken und 3 Eintr√§ge f√ºr die Verweise auf 1 bis 3-fach indizierte Bl√∂cke.**
>
> Wie gro√ü kann eine Datei werden (Berechnungsformel)

```
BS = 1 KiB
BN = 32 Bit (immer bei ext2)

Anzahl Eintraege indirekte Bloecke = BS (in Bit) / BN = 1024 * 8 / 32 = 256

Max. Groesse = Direkte * BS + Anzahl Eintraege indirekte Bloecke ^ Indizierungslevel * BS
Max. Groesse = 12 * 1 KiB + 256 * 1 KiB + 256^2 * 1 KiB + 256 ^ 3 * 1 KiB
```

---

> ![](./assets/SCR-20230618-ohjd.png)
> 
> **Ein Dateisystem sei wie im Bild aufgebaut. Die Blockgr√∂√üe sei `1kB`.**
>
> Was stellt die linke Grafik dar, was die rechte?

Links: Wurzelverzeichnis, Rechts: FAT

> Wie lange ist die Datei (erste Zeile) maximal?

3 -> 5 -> 8 -> 2 -> 9 -> 0xffff => 5 Schritte = max. 5 * 1 KiB

> Um welches Dateisystem handelt es sich?

FAT16 (weil 0xffff = 16 Bit)

> Welche Angabe fehlt, um die genaue Dateigr√∂√üe zu bestimmen?

Das genaue Ende der Datei im Block. 1 Block wird immer verwendet, muss aber nicht ausgefuellt sein. Dadurch groesse so nicht bestimmbar.
Wir braeuchten noch aus den Meta Daten die Groesse.

---






## Prozesskommunikation

> Wie kann der Empf√§nger vom Senden der Nachricht informiert werden, wenn er nicht dauernd nachfragen will?

* **Signale**: Der sendende Prozess sendet ein Signal an den empfangenden Prozess, um ihn √ºber eine neue Nachricht zu informieren. Der empfangende Prozess hat einen Signal-Handler, der das Signal abf√§ngt und die Nachricht verarbeitet.

* **Systemaufrufe**: Der sendende Prozess verwendet einen spezifischen Systemaufruf, um den empfangenden Prozess √ºber die Nachricht zu benachrichtigen. Der empfangende Prozess ruft den entsprechenden Systemaufruf auf, um die Nachricht abzurufen.

* **Synchronisationsmechanismen**: Es werden Synchronisationsmechanismen wie Semaphore, Mutex oder Bedingungsvariablen eingesetzt. Der sendende Prozess setzt einen entsprechenden Synchronisationspunkt, um den empfangenden Prozess zu benachrichtigen. Der empfangende Prozess √ºberpr√ºft den Synchronisationspunkt und liest die Nachricht, wenn sie verf√ºgbar ist.

---

> **Ein Prozess m√∂chte einem anderen Prozess Nachrichtenbl√∂cke variabler L√§nge schicken. Der Empf√§nger m√∂chte die Nachricht mit einem Aufruf lesen, ohne die L√§nge der Nachrichten zu kennen.**
>
> Welches Kommunikationsmittel sollte man daf√ºr verwenden?

Verwendung einer Nachrichtenwarteschlange (**Message Queue**).

* erm√∂glicht die √úbertragung von Nachrichten zwischen Prozessen.
* Nachrichten k√∂nnen variable L√§ngen haben.
* Nachrichtenwarteschlange funktioniert als Pufferstruktur.
* Der sendende Prozess schreibt Nachrichtenbl√∂cke in den Puffer.
* Der empfangende Prozess liest die Nachrichtenbl√∂cke aus dem Puffer.
* Puffer kann verschiedene L√§ngen von Nachrichten aufnehmen.

---

> Vergleichen Sie die Eigenschaften von Pipes und Message-Queues

**Pipes**

* Unnamed und Named Pipes
    * Unnamed entstehen bei Fork zwischen Vater und Kind Prozessen
    * Named koennen zwischen allen Prozessen enstehen (Verwandschaftsgrad egal)
* Unidirektionale Kommunikation
* FIFO (First-In-First-Out) Datenfluss
* Verbindung zwischen verwandten Prozessen
* Implementiert mit Dateideskriptoren
* Begrenzter Puffer

**Message-Queues**

* Bidirektionale Kommunikation
* Nicht-FIFO oder Priorit√§ten beim Lesen
* Verbindung zwischen beliebigen Prozessen
* Implementiert als Kernel-Objekte
* Flexible Puffergr√∂√üe

---

> Was sind Signale?

Signale sind Ereignisse oder Benachrichtigungen, die einem Prozess gesendet werden, um auf bestimmte Ereignisse hinzuweisen oder bestimmte Aktionen auszul√∂sen.
Sie dienen der Kommunikation und Koordination zwischen Prozessen oder zwischen dem Betriebssystem und einem Prozess.

> Wie werden sie behandelt?

Ein Prozess kann Signale empfangen und darauf reagieren, indem er Signal-Handler-Funktionen definiert.
Der Prozess kann Signal-Handler registrieren, um auf bestimmte Signale zu reagieren und entsprechende Aktionen auszuf√ºhren.
Es gibt verschiedene M√∂glichkeiten, Signale zu behandeln, einschlie√ülich Ignorieren des Signals, Ausf√ºhren einer Standardaktion oder Ausf√ºhren einer benutzerdefinierten Aktion.
Einige Signale k√∂nnen blockiert werden, um ihre Ausf√ºhrung vor√ºbergehend zu verhindern.
Signale k√∂nnen auch an andere Prozesse gesendet werden, um mit ihnen zu kommunizieren oder bestimmte Aktionen auszul√∂sen.

---

> Warum kann man einzelne Signale nicht √ºberladen?

Einzelne Signale k√∂nnen nicht √ºberladen werden, da sie standardisierte Bedeutungen haben, die konsistent und interoperabel sein m√ºssen. Die einheitliche Signalbehandlung erleichtert die Systemimplementierung, -leistung und -vorhersagbarkeit.

---

> Warum kann man Signale √ºberladen?

* Signale k√∂nnen maskiert werden, um vor√ºbergehend ihre Behandlung zu unterdr√ºcken.
* Maskierte Signale werden von einem Prozess ignoriert und nicht verarbeitet.
* Maskierte Signale werden in einer Signalmaske gespeichert, die vom Betriebssystem verwaltet wird.
* Das Maskieren von Signalen erm√∂glicht die Steuerung der Signalverarbeitung auf granularer Ebene.
* Maskierte Signale k√∂nnen sp√§ter wieder entsperrt werden und werden dann normal verarbeitet.

---

> Was ist ein Semaphor? Wie wird er verwendet?

* Ein Semaphore ist eine Synchronisationsprimitive.
* Es ist ein ganzzahliger Z√§hler im Kernel.
* werden verwendet, um den Zugriff auf gemeinsame Ressourcen zu steuern.
* helfen bei Synchronisation und Koordination von Prozessen/Threads.

Wenn auf 0 wird blockiert, wenn er benutzt wird, um 1 dekrementiert, wenn nicht mehr benutzt, um 1 inkrementiert.

---













## Prozesse

> **Was ist ein Prozess?**

Als Prozesse bezeichnet man **Programme**, die im **Hauptspeicher** zur Ausf√ºhrung kommen.

![](./assets/Screenshot%202023-06-18%20181714.png)

> Welche Zust√§nde kann er einnehmen?

`wartend`, `ausgelagert`, `bereit`, ...

> Wie gelangt er von einem Zustand in einen anderen?

`wartend` -> `ausgelagert` = `Auslagerung`, ...

---

> Erkl√§ren Sie Multilevel Feedback Scheduling

* Annahme: Dialogorientierte Prozesse ben√∂tigen wenig Rechenzeit, fordern jedoch kurze Antwortzeiten.
* Beim Start: Prozess erh√§lt die h√∂chste Priorit√§t.
* Nutzung der Zeitscheibe: Wenn Prozess Zeitscheibe im n√§chsten Zyklus vollst√§ndig ausnutzt, wird er in eine tiefere Priorit√§tsebene versetzt.
* Nicht-Ausnutzung der Zeitscheibe: Wenn der Prozess die Zeitscheibe nicht vollst√§ndig ausnutzt, verbleibt er in der Startpriorit√§t.
* Ergebnis: Rechenintensive Prozesse werden immer weiter abgestuft, w√§hrend Prozesse, die in der Regel ihre Zeitscheibe nicht nutzen (wie Dialogprozesse), bevorzugt den Prozessor erhalten.

---

> Nennen Sie 2 Gr√ºnde/Vorteile, weshalb diese Methode eingesetzt wird

* Priorisierung von dialogorientierten Prozessen
* Effiziente Ressourcennutzung
* Versetzung rechenintensiver Prozesse in tiefere Priorit√§tsebenen
* Gr√∂√üere Chance f√ºr dialogorientierte Prozesse, den Prozessor zu nutzen
* Ausgewogenere Auslastung des Systems

---

> Was ist ein Thread?

* Eine ausf√ºhrbare Einheit innerhalb eines Prozesses.
* erm√∂glichen die parallele Ausf√ºhrung mehrerer Aufgaben innerhalb eines Prozesses.
* teilt sich den Speicherbereich mit anderen Threads desselben Prozesses.
* Threads k√∂nnen auf globale Daten und Variablen des Prozesses zugreifen.
* Threads k√∂nnen unabh√§ngige Aufgaben ausf√ºhren und den Prozessor freiwillig abgeben.

---

> Wie verhalten sich Prozesse gegen√ºber Threads?

* Prozesse sind eigenst√§ndige Ausf√ºhrungseinheiten, w√§hrend Threads innerhalb eines Prozesses existieren.
* Prozesse haben einen eigenen Adressraum, Threads teilen sich den Adressraum eines Prozesses.
* Prozesse sind isoliert und k√∂nnen nicht direkt auf den Speicher oder die Variablen anderer Prozesse zugreifen, Threads k√∂nnen auf gemeinsam genutzte Ressourcen (im selben Prozess) zugreifen.
* Prozesse erfordern eine Kontextumschaltung, um zwischen ihnen zu wechseln, Threads k√∂nnen direkt gewechselt werden.
* Threads haben weniger Overhead und ben√∂tigen weniger Ressourcen im Vergleich zu Prozessen.
* Threads k√∂nnen parallel ausgef√ºhrt werden und die CPU-Ressourcen effizient nutzen.

---

> Was sind KLTs (Kernel-Level Threads)?

* KLTs werden vom Betriebssystem auf Kernenebene verwaltet.
* Erzeugen und Verwalten von KLTs erfordert Systemcalls.
* KLTs k√∂nnen blockierende Systemcalls verwenden.
* Betriebssystem gew√§hrt KLTs Prozessorzeit basierend auf der Scheduling-Strategie.

> Was sind ULTs (User-Level Threads)?

* ULTs werden auf Anwendungsebene durch eine Thread-Bibliothek verwaltet.
* ULTs sind Teil desselben Prozesses und teilen sich den Adressraum.
* ULTs erfordern keine Systemcalls f√ºr Erzeugung und Verwaltung.
* ULTs m√ºssen die CPU-Ressourcen freiwillig abgeben (yield) oder asynchrone Systemaufrufe verwenden.
* Das Betriebssystem betrachtet ULTs als einen einzigen Prozess und gew√§hrt ihm Prozessorzeit.

---

> Zeigen Sie die Speicherbelegung von Threads

![](./assets/Screenshot%202023-06-18%20183119.png)

---

> Welcher Typ von Threads kann ein Mehrprozessorsystem nutzen? Warum?

KLTs k√∂nnen ein Mehrprozessorsystem nutzen, da jeder Thread als eigenst√§ndiger Prozess anerkannt wird und auf mehrere Prozessoren aufgeteilt werden kann. 
Bei ULT werden alle Threads als ein Prozess erkannt -> schlecht

---

> Sie haben mehrere Threads, die ihre Ergebnisse in einer gemeinsamen Variable aufsummieren.
> K√∂nnen Sie, da die Addition kommutativ ist, auf kritische Bereiche verzichten?

Nein, auf kritische Bereiche kann nicht verzichtet werden, weil die Addition einer Zahl auf eine gemeinsame Variable und √ºberschreiben dieser Variable nicht in einem Befehl m√∂glich ist. Dadurch w√ºrden Inkonsistenzen entstehen. 

> Wenn nein, wie w√ºrden Sie das Problem l√∂sen?

Ein Semaphor k√∂nnte eingesetzt werden. Dabei handelt es sich um einen im Kernel 
befindlichen Z√§hler, der anzeigt, ob die gemeinsame Variable gerade in Benutzung ist 
oder nicht. Ein Prozess kann einen Semaphor belegen und freigeben.

---

> Was sind Memory Mapped Files?

Memory Mapped Files sind eine Technik zur Abbildung von Dateien in den Arbeitsspeicher eines Computers. Durch die Verwendung von Memory Mapped Files kann auf den Inhalt einer Datei direkt √ºber Speicherzugriffe zugegriffen werden, ohne dass explizite Lese- oder Schreiboperationen durchgef√ºhrt werden m√ºssen.

> Beschreiben Sie die Funktionsweise

* Beim Aufruf `mmap()` wird ein bestimmter Ausschnitt einer Datei im virtuellen Adressraum eines Prozesses abgebildet.
* Beim Zugriff auf den abgebildeten Speicherbereich wird ein Page Fault ausgel√∂st, da die Daten m√∂glicherweise nicht im Hauptspeicher vorhanden sind.
* Das Betriebssystem l√§dt die entsprechende Seite der Datei in den Hauptspeicher und setzt die Anwendung mit dem fehlgeschlagenen Befehl fort.
* Der Prozess kann nun direkt auf den Inhalt der Datei √ºber Speicherzugriffe zugreifen, ohne explizite Lese- oder Schreiboperationen durchzuf√ºhren.
* √Ñnderungen im Speicher werden automatisch in die Datei geschrieben, und Lesen aus dem Speicher liefert den aktuellen Inhalt der Datei.
* Memory Mapped Files erm√∂glichen effizienten Zugriff auf gro√üe Dateien und vereinfachen den Umgang mit Dateiinhalten durch die Nutzung von Speicherzugriffen.

---

**Copy-On-Write:**

> Warum f√ºhrt `copy_on_write` zur beschleunigten Ausf√ºhrung eines Child-Prozesses nach `fork()`

Die beschleunigte Ausf√ºhrung eines Child-Prozesses nach `fork()` wird durch die Copy-on-Write-Strategie erm√∂glicht. Dabei greifen beide Prozesse √ºber ihre Pagetable, es gibt zwei, auf den gleichen Anwendungsadressraum zu. Die Eintr√§ge in der Pagetable sind schreibgesch√ºtzt (W = 0). Wenn einer der Prozesse schreiben m√∂chte, wird eine Exception ausgel√∂st, woraufhin die Page kopiert und der Schreibschutz der entsprechenden Eintraegen der Pagetable entfernt wird. Dadurch wird Speicher effizient genutzt, da Kopien und Ressourcenallokation nur bei tats√§chlichen Schreibzugriffen erfolgen. Dies f√ºhrt zu einer beschleunigten Ausf√ºhrung des Child-Prozesses.

> Was geschieht, wenn einer der Prozesse eine Globalvariable modifiziert?

` üö® answer missing `

> Was geschieht bei einem Unterprogrammaufruf?

Zur Ausf√ºhrung des Systemcalls `exec()`, wird der komplette Adressraum des Kindes √ºberschrieben. 
Dann muss der vollst√§ndige neue Adressraum gebildet werden, bzw. bildet er sich durch Demand Paging auch wieder nur im ben√∂tigten Umfang neu.

---

> Warum wird bei Linux und Windows der Anwendungsadressraum von 4GB auf 3GB (Windows 2GB) verkleinert?

* Platz f√ºr das Betriebssystem im reservierten Adressraum
* Linux reserviert 1GB, Windows 2-3GB f√ºr das Betriebssystem
* Diese Reduzierung erm√∂glicht es, dass das Betriebssystem und die Anwendungen beide Adressr√§ume gleichzeitig sichtbar haben. Bei 64-Bit-CPUs ist diese Einschr√§nkung nicht erforderlich.

> Welche Vorteile hat diese Ma√ünahme bei einem Systemcall

* Direkter Zugriff des Betriebssystems auf virtuelle Adressen der Anwendung
* Keine Umrechnung der Adressen erforderlich
* Kein Wechsel zwischen Adressr√§umen
* Vermeidung von TLB- und Cache-Invalidierungen
* Beschleunigung der Systemaufrufe

> Welche Vorteile hat diese Ma√ünahme beim Datentransfer

* Das Betriebssystem kann beim Zugriff auf Anwendungsdaten die virtuellen Adressen (Pointer) verwenden ohne sie umzurechnen, oder zwischen verschiedenen Adressraeumen umschalten zu muessen
* Auch TLB und der Cache muessen beim Eintritt ins Betriebssystem nicht invalidiert werden

---

> Was ist eine Race-Condition?

Eine Race-Condition ist eine Situation, in der das Verhalten eines Programms oder Systems davon abh√§ngt, in welcher Reihenfolge die einzelnen Threads oder Prozesse ausgef√ºhrt werden.

> Welche Fehler k√∂nnen auftreten?

M√∂gliche Fehler, die durch Race-Conditions auftreten k√∂nnen, sind:

* Inkonsistente oder fehlerhafte Ergebnisse aufgrund von parallelen Aktualisierungen von gemeinsam genutzten Ressourcen.
* Deadlocks oder Blockaden, bei denen Threads oder Prozesse aufeinander warten und dadurch das System blockiert wird.
* Datenverlust oder Datenbesch√§digung durch inkonsistente Schreib- oder Leseoperationen.

> Wie kann man diese vermeiden?

* Synchronisierung: Verwendung von Mechanismen wie Mutexes (Sperren) oder Semaphoren, um den Zugriff auf gemeinsam genutzte Ressourcen zu koordinieren und sicherzustellen, dass nur ein Thread oder Prozess gleichzeitig darauf zugreift.
* Kritische Abschnitte: Identifizierung und Kennzeichnung von kritischen Abschnitten im Code, in denen gemeinsam genutzte Ressourcen verwendet werden, und deren sch√ºtzende Umrahmung mit Synchronisierungsmechanismen.
* Atomare Operationen: Verwendung von atomaren Operationen, die als unteilbare Einheiten ausgef√ºhrt werden und keine Race-Conditions verursachen k√∂nnen.
* Thread-Sicherheit: Entwicklung und Gestaltung von Code und Algorithmen, die sicher in einem Mehrbenutzer-/Mehrprozessorsystem ausgef√ºhrt werden k√∂nnen, indem m√∂gliche Race-Conditions von vornherein vermieden werden.

---

> F√ºnf Auftr√§ge warten auf ihren Start. Ihre erwarteten Laufzeiten sind 9, 5, 3 und 5 sec.
> In welcher Reihenfolge sollten sie laufen, damit die mittlere Antwortzeit minimiert wird?

Von der kuerzesten Zeit zur laengsten Zeit, also `3`, `5`, `5`, `9`.
Mittlere Antwortzeit ist (3 + 8 + 13 + 22) / 4 = 11.5

---

> Warum werden Seiten ausgelagert?

Seiten werden ausgelagert, um **Speicherplatz im Hauptspeicher freizugeben** und **Platz f√ºr andere Seiten oder Prozesse zu schaffen**. Dies geschieht, wenn der verf√ºgbare Hauptspeicher nicht ausreicht, um alle aktiven Seiten aller laufenden Prozesse zu halten.

> Was geschieht dabei?

Beim Auslagern einer Seite wird der Inhalt dieser Seite vom Hauptspeicher auf die Festplatte oder ein anderes sekund√§res Speichermedium verschoben. Dadurch wird der Speicherplatz im Hauptspeicher freigegeben, und die Seite wird als "ausgelagert" markiert. Wenn die Seite sp√§ter wieder ben√∂tigt wird, kann sie vom sekund√§ren Speicher in den Hauptspeicher zur√ºckgeladen werden.

> Welche Strategien gibt es?

**Optimal**

Diese Strategie existiert nur theoretisch. Dabei m√ºsste man in die Zukunft sehen k√∂nnen, um herauszufinden, welche Seite nie wieder bzw. am sp√§testen wieder gebraucht wird.

**FIFO**

Beim Einlagern einer Seite in den Hauptspeicher wird sie mit einem Zeitstempel versehen. Wenn der Hauptspeicher zu voll wird, werden Seiten mit dem fr√ºhesten Zeitstempel als erstes verdr√§ngt.
‚Üí In den meisten F√§llen sinnlos, da System-Dienste fr√ºh gestartet werden und immer gebraucht werden

**Clock-Algorithmus**

Zwei Zeiger durchlaufen hintereinander mit etwas Abstand die Pages im RAM. 
Der vordere Zeiger setzt das Access-Bit jeder Seite auf 0. Wenn auf eine Seite 
zugegriffen wird, wird dieses Bit auf 1 gesetzt. 
Der hintere Zeiger prueft, ob das Access-Bit auf 0 gesetzt ist, ist dies der Fall, wird die Seite ausgelagert.

**LRU**

F√ºr jede Seite wird ein Bit-Vektor gespeichert. Direkt nach der Einlagerung sind 
alle Bits 0. In regelm√§√üigen Zeitabst√§nden pr√ºft nun das BS f√ºr jede Page im 
HS ihr Access-Bit und schiebt es an den Anfang des Bit-Vektors, so dass sich 
die anderen Bits um eine Stelle verschieben und ein Bit hausf√§llt. Anschlie√üend 
setzt er das Access-Bit auf 0.
Sieht man den Bit-Vektor als Bin√§rzahl an, gibt diese Zahl eine Aussage 
dar√ºber, wie oft in letzter Zeit auf diese Page zugegriffen wurde. Pages mit 
niedrigerer Zahl k√∂nnen also eher ausgelagert werden.

---

> Was ist ein "Seitenfehler"?

Ein "Seitenfehler" (auch bekannt als Page Fault) tritt auf, wenn ein Prozess auf eine Seite im virtuellen Speicher zugreifen m√∂chte, die sich nicht im Hauptspeicher befindet.

> Wodurch wird er verursacht?

* Die angeforderte Seite wurde noch nicht in den Hauptspeicher geladen, da sie entweder noch nicht ben√∂tigt wurde oder zuvor ausgelagert wurde.
* Die angeforderte Seite wurde ausgelagert, um Platz f√ºr andere Seiten oder Prozesse zu schaffen.
* Es kann ein Fehler im Adressraum des Prozesses vorliegen, der dazu f√ºhrt, dass auf ung√ºltige Adressen zugegriffen wird.

> Welche grunds√§tzlichen Reaktionen darauf gibt es?

* Laden: Die angeforderte Seite wird vom sekund√§ren Speicher (z. B. Festplatte) in den Hauptspeicher geladen, damit der Prozess darauf zugreifen kann. Der Prozess wird dann fortgesetzt, als ob nichts passiert w√§re.
* Austauschen: Wenn der Hauptspeicher voll ist, muss eine andere Seite ausgelagert werden, um Platz f√ºr die angeforderte Seite zu schaffen. Die ausgelagerte Seite wird auf die Festplatte verschoben, und die angeforderte Seite wird an ihre Stelle im Hauptspeicher geladen.
* Fehlerbehandlung: Wenn der Seitenfehler auf einen ung√ºltigen Zugriff oder einen anderen schwerwiegenden Fehler hinweist, kann das Betriebssystem den Prozess beenden oder eine entsprechende Fehlerbehandlung durchf√ºhren

---









## Virtualisierung

> Was ist ein Typ-1 Hypervisor?

**Typ-1 Hypervisor (Bare-Metal Hypervisor):**

* **Das Gastsystem laeuft in einer niedrigen Privilegstufte**
    * Kritische oder sensitive Instruktionen werfen eine Exception.
    * Werden von der VMM (Virtual Machine Monitor) abgearbeitet.
* Wird auch als "Bare-Metal Hypervisor" bezeichnet.
* Wird direkt auf der physischen Hardware (ohne ein Host-Betriebssystem) installiert.
* Hat direkten Zugriff auf die Hardware-Ressourcen des Systems.
* Bietet eine hohe Leistung und Effizienz, da kein Host-Betriebssystem vorhanden ist.

> Was ist ein Typ-2 Hypervisor?

**Typ-2 Hypervisor (Hosted Hypervisor):**

* Wird auch als "Hosted Hypervisor" bezeichnet.
* Wird auf einem Host-Betriebssystem installiert.
* Teilt die Hardware-Ressourcen des Host-Betriebssystems mit den virtualisierten G√§sten.
* Hat weniger direkten Zugriff auf die Hardware als ein Typ-1 Hypervisor.
* Bietet eine h√∂here Flexibilit√§t, da das Host-Betriebssystem verschiedene Anwendungen ausf√ºhren kann.
* Wird h√§ufig auf Desktop-Computern f√ºr Virtualisierungszwecke verwendet.

---

> Was ist die Voraussetzung eines Typ-1 Hypervisors?

* Erfordert eine physische Hardware, auf der er direkt ausgef√ºhrt werden kann.
* Ben√∂tigt Zugriff auf die grundlegenden Hardware-Ressourcen des Systems, wie CPU, Speicher, Festplatten und Netzwerkger√§te.
* Die Hardware sollte Virtualisierungstechnologien unterst√ºtzen, z. B. Intel VT-x oder AMD-V, um die Virtualisierungseffizienz zu verbessern.
* Der Hypervisor ben√∂tigt m√∂glicherweise spezifische Treiber f√ºr die Hardware-Komponenten, um eine optimale Leistung und Funktionalit√§t zu gew√§hrleisten.

---

> Was ist die Voraussetzung eines Typ-2 Hypervisors?

* Die Installation eines Typ-2 Hypervisors erfordert ein Host-Betriebssystem auf der physischen Hardware.
* Das Host-Betriebssystem sollte f√ºr die Virtualisierung geeignet sein und die Installation und Ausf√ºhrung von Hypervisor-Software erm√∂glichen.
* Der Hypervisor nutzt die Ressourcen des Host-Betriebssystems, einschlie√ülich der Hardware-Ressourcen wie CPU, Speicher und Netzwerk.
* Die Hardware des Systems sollte Virtualisierungstechnologien unterst√ºtzen, um die Virtualisierungsleistung zu verbessern.
* Der Typ-2 Hypervisor kann von den Funktionen und Treibern des Host-Betriebssystems abh√§ngig sein, um eine optimale Funktionalit√§t zu bieten.

---

> Wie verhindert ein Typ-1 Hypervisor, dass ein Gastsystem direkt auf die Hardware zugreift?

* Die Privilegstufe der Gastsysteme wird heruntergesetzt
* Er besteht aus einer Virtual Machine Monitor (VMM) Schicht, die den direkten Zugriff auf die Hardware erm√∂glicht.
* Der Hypervisor kontrolliert den Zugriff auf die physischen Ressourcen wie Prozessor, Speicher, Netzwerk und Speichermedien.
* Er stellt eine virtuelle Umgebung f√ºr die Gastsysteme bereit, in der sie ausgef√ºhrt werden k√∂nnen.
* Der Hypervisor bietet eine hohe Leistung und Effizienz, da er direkt mit der Hardware interagiert.
* Durch die Isolierung der Gastsysteme voneinander und vom Hypervisor wird die Sicherheit und Stabilit√§t gew√§hrleistet.

---

> Wie verhindert ein Typ-2 Hypervisor, dass ein Gastsystem direkt auf die Hardware zugreift?

* Er greift nicht direkt auf die physische Hardware zu, sondern nutzt die Treiber und Schnittstellen des Host-Betriebssystems.
* Der Hypervisor arbeitet als Schicht zwischen dem Host-Betriebssystem und den Gastsystemen.
* Der Host-Betriebssystem kontrolliert den Zugriff auf die Hardware-Ressourcen und stellt sie dem Hypervisor zur Verf√ºgung.
* Der Hypervisor erm√∂glicht die Ausf√ºhrung mehrerer Gastsysteme als separate virtuelle Maschinen.
* Durch den sicheren Zugriff auf die physischen Ressourcen durch den Hypervisor werden die Gastsysteme voneinander isoliert und gesch√ºtzt.

---

> **Bei modernen Systemen ist die Virtualisierung schon von Haus aus im Prozessor integriert.**

> Welchen zus√§tzlichen Hardwarebaustein braucht man, um Nested Page Tables zu unterst√ºtzten?

MMU-VM

> Welche Eigenschaften muss ein Peripherieger√§t vorweisen, um I/O-Virtualisierung zu unterst√ºtzen?

` üö® answer missing `

---

> Was ist ein Container?

![](./assets/Screenshot%202023-06-18%20194107.png)

* Container bieten Anwendungen eine abgeschottete Umgebung, die unabh√§ngig von anderen Containern ist.
* Container teilen sich das gleiche Betriebssystem, erm√∂glichen aber die Einbindung unterschiedlicher Versionen von Bibliotheken.
* Container bestehen aus Images, die den Inhalt des Containers sowie die Startparameter enthalten.
* Die Container-Engine ist f√ºr das Starten, Stoppen und Verwalten der Container zust√§ndig.
* Die Container-Engine erm√∂glicht die Kommunikation zwischen den Containern sowie mit Anwendungen au√üerhalb der Container und des Host-Rechners.

---

> Was ist ein Emulator?

* Emulation erm√∂glicht die Nachbildung beliebiger Systeme.
* Ein Emulator liest den Bin√§rcode des emulierten Systems aus und f√ºhrt ihn Befehl f√ºr Befehl in einem Softwaremodell des Prozessors oder des gesamten Systems aus.
* Emulationssysteme eignen sich haupts√§chlich f√ºr Entwicklung und Testzwecke.
* Die Geschwindigkeit eines emulierten Systems ist im Vergleich zum Originalsystem meist deutlich geringer, typischerweise nur 20-30% der Leistung.
* Emulatoren wie Qemu und Bochs sind Beispiele f√ºr solche Systeme.
* Wine ist ein spezieller Fall, bei dem eine virtuelle Betriebssystemschnittstelle bereitgestellt wird, um Windows-Anwendungen auf Linux-Systemen auszuf√ºhren.

---

> Was ist eine I/O-MMU? Und wof√ºr wird sie verwendet?

* Eine I/O-MMU wird verwendet, um den direkten Zugriff von Gastbetriebssystemen auf virtuelle Ger√§te zu erm√∂glichen.
* Der direkte Zugriff auf virtuelle Ger√§te kann jedoch Gefahren f√ºr die Gesamtfunktion des Systems mit sich bringen, insbesondere wenn die Ger√§te DMA-f√§hig sind.
* DMA (Direct Memory Access) erlaubt es Ger√§ten, Daten direkt zwischen dem Arbeitsspeicher und dem Ger√§t zu √ºbertragen, ohne die CPU zu belasten.
* Die I/O-MMU √§hnelt einer MMU (Memory Management Unit) und verwendet Seitentabellen, um Adressen von virtuellen Ger√§ten auf physikalische Adressen im Arbeitsspeicher abzubilden.
* Die I/O-MMU wird vom VMM (Virtual Machine Monitor) parametriert und erm√∂glicht den Gastsystemen, dieselben DMA-Adressen zu verwenden, w√§hrend die I/O-MMU die Zuordnung zu den physikalischen Adressr√§umen der virtuellen Maschinen vornimmt.
* Die I/O-MMU gew√§hrleistet einen sicheren und effizienten Zugriff der Gastsysteme auf virtuelle Ger√§te und erm√∂glicht eine sichere Kommunikation zwischen den virtuellen Maschinen und den virtuellen Ger√§ten.

---




## Systemaufrufe

> **Erkl√§ren Sie die Funktion und Wirkungsweise folgender System-Calls:**

* `fork()`: Erzeugt einen neuen Prozess, der eine exakte Kopie des aufrufenden Prozesses ist. Der neue Prozess, auch Kindprozess genannt, erh√§lt eine eindeutige Prozesskennung (PID) und eine Kopie des Adressraums, der Dateideskriptoren und anderer Ressourcen des Elternprozesses.
* `wait()`: Blockiert den Elternprozess und wartet auf die Beendigung eines oder mehrerer Kindprozesse. Der Aufruf von `wait()` erm√∂glicht es dem Elternprozess, auf den Abschluss der Ausf√ºhrung seiner Kindprozesse zu warten, bevor er selbst fortf√§hrt.
* `exit()`: Beendet den aktuellen Prozess und gibt Ressourcen frei. Optional kann ein Beendigungsstatus √ºbergeben werden.
* `exec()`: Startet ein neues Programm in einem Prozess, indem der aktuelle Programmcode durch den Code des neuen Programms ersetzt wird.

---

> Beschreiben Sie den Ablauf eines Systemcalls am Beispiel des Aufrufs `write()` in eine Datei.

System-Calls werden durch Interrupts realisiert. Dazu wechselt eine Anwendung mittels eines Software-Interrupts in den Kontext des BS. Dort wird der Auftrag ausgewertet und an den Treiber weitergeleitet. Dieser wandelt den abstrakten Auftrag in einen Auftrag um, der von den entsprechenden Ger√§ten verstanden wird. Der Treiber gibt nun die CPU frei. Sobald das Ger√§t seine Auswertung abgeschlossen hat, wird ein Interrupt an den Treiber geschickt. Der Treiber informiert anschlie√üend den Scheduler, welcher wiederum √ºber die weitere Ausf√ºhrung entscheidet. Per Iret wird nun die Interruptreaktionsroutine beendet.

---

> Wozu dienen Interrupts ausgel√∂st durch Hardware?

* Behandlung von Hardwareereignissen: Hardware-Interrupts werden von physischen Ger√§ten, wie z.B. Tastaturen, M√§usen, Netzwerkkarten oder Timern, ausgel√∂st. Sie signalisieren dem Prozessor, dass eine bestimmte Aktion oder ein Ereignis eingetreten ist, das Aufmerksamkeit erfordert.
* Echtzeitverarbeitung: Hardware-Interrupts erm√∂glichen es dem System, auf zeitkritische Ereignisse sofort zu reagieren. Beispielsweise kann ein Interrupt ausgel√∂st werden, wenn ein Netzwerkpaket eingetroffen ist, um es schnell zu verarbeiten und zu reagieren.

---

> Wozu dienen Interrupts ausgel√∂st durch Software?

* Betriebssystemsteuerung: Software-Interrupts, auch als Trap oder Software Trap bezeichnet, werden vom Betriebssystem selbst oder von Anwendungen ausgel√∂st, um eine bestimmte Funktion im Betriebssystem auszuf√ºhren. Sie dienen dazu, vom Benutzer angeforderte Systemdienste oder Betriebssystemfunktionen zu aktivieren, z.B. das √ñffnen einer Datei oder das Ausf√ºhren eines bestimmten Befehls.
* Synchronisation und Koordination: Software-Interrupts werden auch verwendet, um die Kommunikation und Koordination zwischen verschiedenen Prozessen oder Threads innerhalb des Systems zu erm√∂glichen. Sie k√∂nnen dazu verwendet werden, Signale oder Ereignisse zu senden, um auf bestimmte Bedingungen zu warten oder um eine asynchrone Kommunikation zwischen verschiedenen Teilen des Systems zu erm√∂glichen.

---








## Treiber

> Was ist ein Device-Switch-Table?

* Device-Switch-Table ist eine Datenstruktur im Betriebssystem.
* Sie verwaltet den Zugriff auf verschiedene Ger√§te (Hardware oder virtuelle Ger√§te).
* Jedes Ger√§t hat einen Eintrag in der Tabelle.
* Die Tabelle enth√§lt Informationen und Funktionen zur Steuerung und Kommunikation mit den Ger√§ten.
* Sie abstrahiert die Ger√§tekommunikation und bietet eine einheitliche Schnittstelle.
* Betriebssystem kann auf die Funktionen in der Tabelle zugreifen, um Ger√§teaktionen auszuf√ºhren.
* Sie erm√∂glicht einfache Erweiterung des Systems um neue Ger√§te.
* Wichtiger Bestandteil des Ger√§tetreiber-Frameworks.

---

> Was bedeutet Minor- und Major-Number?

**Major-Number:** Die Major-Number identifiziert den Ger√§tetreiber, der ein bestimmtes Ger√§t in einem Betriebssystem unterst√ºtzt. Sie stellt eine eindeutige Kennung f√ºr den Treiber dar und wird verwendet, um den entsprechenden Treiber im Kernel zu identifizieren.

**Minor-Number:** Die Minor-Number wird verwendet, um ein spezifisches Ger√§t zu identifizieren, das von einem bestimmten Treiber unterst√ºtzt wird. Sie erm√∂glicht die Unterscheidung zwischen verschiedenen Ger√§ten desselben Treibers. Die Minor-Number kann verwendet werden, um auf bestimmte Ger√§teinstanzen oder Funktionen innerhalb eines Ger√§tetreiberbereichs zuzugreifen.

Zusammen bilden die Major- und Minor-Numbers eine eindeutige Kennung f√ºr ein Ger√§t in einem Unix-System.

---

> Was sind Block-Devices?

* Block-Ger√§te sind Ger√§te, die Daten in Bl√∂cken (festgelegte Datenmengen) verarbeiten.
* Sie erm√∂glichen den zuf√§lligen Zugriff auf Datenbl√∂cke und unterst√ºtzen Lese- und Schreibvorg√§nge in gr√∂√üeren Einheiten.
* Typische Beispiele f√ºr Block-Ger√§te sind Festplatten, Solid-State-Laufwerke (SSDs) und CD/DVD-Laufwerke.
* Block-Ger√§te werden normalerweise zur Speicherung und √úbertragung gro√üer Datenmengen verwendet.

> Character Devices?

* Character-Ger√§te sind Ger√§te, die Daten zeichenweise verarbeiten.
* Sie erm√∂glichen den sequenziellen Zugriff auf Daten, d.h. die Daten werden in der Reihenfolge ihres Eintreffens verarbeitet.
* Typische Beispiele f√ºr Character-Ger√§te sind Tastaturen, M√§use, serielle Schnittstellen und Soundkarten.
* Character-Ger√§te werden oft f√ºr die Eingabe und Ausgabe von Daten verwendet, die in Echtzeit erfolgen oder eine zeichenweise Verarbeitung erfordern.

---

> Welche Aufgaben hat ein Ger√§tetreiber?

- Bereitstellung einer allgemeinen Ger√§teschnittstelle
- Abstraktion der Ger√§tefunktionen (auf read, write, ...)

---

> Was versteht man unter "raw" und "cooked"?

Zeichenorientierte Ger√§te k√∂nnen √ºber diese beiden Schnittstellen angesprochen werden. Die "cooked"-Schnittstelle wird verwendet, um z.B. ganze Eingabezeilen einzulesen. Die Benutzereingaben werden dabei aufbereitet (cook) und Zeichen wie Backspace interpretiert, anstatt sie direkt weiterzugeben. Die "raw"-Schnittstelle gibt alle Zeichen, so wie sie vom Nutzer eingegeben werden, an das System weiter, ohne sie zu interpretieren.

---







## Dialogsysteme

> Beschreiben Sie die Funktionsweise eines Fenstersystems

Ein Fenstersystem teilt den Bildschirm in verschiedene Bereiche (Fenster) ein.
Zuordnung von Eingaben zu aktivem Fenster durch Window-Manager.
Ereignisse (Maus-Klick) -> Hardware-Interrupt -> USB-Treiber -> Window-Manager -> √úbermittlung an Anwendung -> Zur√ºckgeben von Ausgabe

---








## Unkategorisiert

> Welche Instruktionen eines Prozessors m√ºssen privilegiert sein, um einen sicheren Betrieb eines Systems zu gew√§hrleisten?

* Manipulation der Privilegstufen
* Manipulation der Adressierungsmechanismen
* Setzen der Interruptsperre
* Verwenden der I/O-Befehle

---

> Wie wird Shared Memory realisiert?

* Das Reservieren eines gemeinsamen Speicherbereichs im Hauptspeicher des Computers
* Das Zuweisen dieses Speicherbereichs an mehrere Prozesse
* Die Prozesse k√∂nnen dann direkt auf den gemeinsamen Speicherbereich zugreifen und Daten austauschen, ohne Daten zwischen den Prozessen kopieren zu m√ºssen.

> Wozu wird es verwendet?

* Effizienten und schnellen Datenaustausch zwischen Prozessen
* Gemeinsame Nutzung gro√üer Datenmengen ohne Datenkopien
* Kommunikation und Synchronisation zwischen Prozessen in Multithreaded- und Mehrprozessorsystemen
* Implementierung von IPC (Inter-Process Communication)-Mechanismen wie Pipes, Message Queues und Semaphoren.
